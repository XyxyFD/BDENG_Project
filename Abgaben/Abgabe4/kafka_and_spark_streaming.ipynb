{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7449a6ab-a8b8-4a9f-9602-c8c1ca96e2c5",
   "metadata": {},
   "source": [
    "# Kafka and Spark Streaming Exercise\n",
    "\n",
    "**INFORMATION**: This exercise is easier on the cluster!\n",
    "\n",
    "Kafka is an excellent tool for data engineering projects due to its distributed, fault-tolerant, and scalable architecture, which facilitates real-time data streaming and processing. It serves as a highly reliable messaging system that efficiently handles large volumes of data streams from diverse sources. Kafka's ability to decouple data producers from consumers and its support for parallel data processing make it ideal for building robust and scalable data pipelines. Additionally, Kafka's durability and fault-tolerance ensure that data is safely persisted and replicated across nodes, minimizing the risk of data loss and ensuring continuous data availability for downstream applications and analytics.\n",
    "\n",
    "Spark Streaming enables the real-time processing of data streams with high throughput and low latency. It seamlessly integrates with Apache Spark's core APIs, allowing developers to leverage Spark's powerful data processing capabilities for streaming data. Spark Streaming supports a wide range of data sources, including Kafka, Flume, and HDFS, and can process data in near real-time, making it ideal for applications that require instant insights and timely responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60416d6d-a703-4609-9001-93d2439c76f8",
   "metadata": {},
   "source": [
    "Use Python, ```pyspark```, ```pandas```, ```confluent-kafka``` and/or ```kafka-python``` to send messages to a Kafka topic and analyse them with Spark Streaming:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd5c42-0181-452e-a6db-2cd50258ff73",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d33407-639f-40b3-ac6b-96a00f6a01a4",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e8b718-e0b9-42c0-a616-4328fa7a22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "from kafka import KafkaAdminClient\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d90374d-3092-4648-b41d-3338e88e6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelle Topics: ['wikimedia-changes', 'big-data-test', 'music', 'g3-raw-html-test', 'roulette', 'hello-world', 'g3-hello-world', 'flights', '__consumer_offsets', 'stocks']\n"
     ]
    }
   ],
   "source": [
    "admin = KafkaAdminClient(bootstrap_servers=\"172.29.16.101:9092\")\n",
    "\n",
    "\n",
    "\n",
    "# 4) Zum Abschluss die Liste aller Topics anzeigen\n",
    "print(\"Aktuelle Topics:\", admin.list_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f30822",
   "metadata": {},
   "source": [
    "## Load a dataset to stream\n",
    "Select a suitable dataset from previous exercises and split it into individual JSON messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83679da7-1faf-4697-8e9a-14a30a6ff728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              legId  searchDate  flightDate startingAirport  \\\n",
      "0  9ca0e81111c683bec1012473feefd28f  2022-04-16  2022-04-17             ATL   \n",
      "1  98685953630e772a098941b71906592b  2022-04-16  2022-04-17             ATL   \n",
      "2  98d90cbc32bfbb05c2fc32897c7c1087  2022-04-16  2022-04-17             ATL   \n",
      "3  969a269d38eae583f455486fa90877b4  2022-04-16  2022-04-17             ATL   \n",
      "4  980370cf27c89b40d2833a1d5afc9751  2022-04-16  2022-04-17             ATL   \n",
      "\n",
      "  destinationAirport fareBasisCode travelDuration  elapsedDays  \\\n",
      "0                BOS      LA0NX0MC        PT2H29M            0   \n",
      "1                BOS      LA0NX0MC        PT2H30M            0   \n",
      "2                BOS      LA0NX0MC        PT2H30M            0   \n",
      "3                BOS      LA0NX0MC        PT2H32M            0   \n",
      "4                BOS      LA0NX0MC        PT2H34M            0   \n",
      "\n",
      "   isBasicEconomy  isRefundable  ...  segmentsArrivalTimeEpochSeconds  \\\n",
      "0           False         False  ...                       1650223560   \n",
      "1           False         False  ...                       1650200400   \n",
      "2           False         False  ...                       1650218700   \n",
      "3           False         False  ...                       1650227460   \n",
      "4           False         False  ...                       1650213180   \n",
      "\n",
      "          segmentsArrivalTimeRaw  segmentsArrivalAirportCode  \\\n",
      "0  2022-04-17T15:26:00.000-04:00                         BOS   \n",
      "1  2022-04-17T09:00:00.000-04:00                         BOS   \n",
      "2  2022-04-17T14:05:00.000-04:00                         BOS   \n",
      "3  2022-04-17T16:31:00.000-04:00                         BOS   \n",
      "4  2022-04-17T12:33:00.000-04:00                         BOS   \n",
      "\n",
      "   segmentsDepartureAirportCode  segmentsAirlineName segmentsAirlineCode  \\\n",
      "0                           ATL                Delta                  DL   \n",
      "1                           ATL                Delta                  DL   \n",
      "2                           ATL                Delta                  DL   \n",
      "3                           ATL                Delta                  DL   \n",
      "4                           ATL                Delta                  DL   \n",
      "\n",
      "  segmentsEquipmentDescription segmentsDurationInSeconds segmentsDistance  \\\n",
      "0                  Airbus A321                      8940              947   \n",
      "1                  Airbus A321                      9000              947   \n",
      "2               Boeing 757-200                      9000              947   \n",
      "3                  Airbus A321                      9120              947   \n",
      "4                  Airbus A321                      9240              947   \n",
      "\n",
      "  segmentsCabinCode  \n",
      "0             coach  \n",
      "1             coach  \n",
      "2             coach  \n",
      "3             coach  \n",
      "4             coach  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Anzahl Datensätze: 10000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"flight_prices_small.csv\")\n",
    "print(df.head())\n",
    "print(f\"Anzahl Datensätze: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70661a92-f517-427c-924f-61df05d91a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel-Record: {'legId': '9ca0e81111c683bec1012473feefd28f', 'searchDate': '2022-04-16', 'flightDate': '2022-04-17', 'startingAirport': 'ATL', 'destinationAirport': 'BOS', 'fareBasisCode': 'LA0NX0MC', 'travelDuration': 'PT2H29M', 'elapsedDays': 0, 'isBasicEconomy': False, 'isRefundable': False, 'isNonStop': True, 'baseFare': 217.67, 'totalFare': 248.6, 'seatsRemaining': 9, 'totalTravelDistance': 947.0, 'segmentsDepartureTimeEpochSeconds': '1650214620', 'segmentsDepartureTimeRaw': '2022-04-17T12:57:00.000-04:00', 'segmentsArrivalTimeEpochSeconds': '1650223560', 'segmentsArrivalTimeRaw': '2022-04-17T15:26:00.000-04:00', 'segmentsArrivalAirportCode': 'BOS', 'segmentsDepartureAirportCode': 'ATL', 'segmentsAirlineName': 'Delta', 'segmentsAirlineCode': 'DL', 'segmentsEquipmentDescription': 'Airbus A321', 'segmentsDurationInSeconds': '8940', 'segmentsDistance': '947', 'segmentsCabinCode': 'coach'}\n"
     ]
    }
   ],
   "source": [
    "records = df.to_dict(orient=\"records\")\n",
    "print(\"Beispiel-Record:\", records[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5be54",
   "metadata": {},
   "source": [
    "## Create a producer and stream the messages\n",
    "You need to use a Kafka producer to connect to a broker and send the messages to a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de2e4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Nachrichten an Topic 'flights' gesendet.\n"
     ]
    }
   ],
   "source": [
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=\"172.29.16.101:9092\",\n",
    "    value_serializer=lambda v: json.dumps(v).encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "topic = \"flights\"\n",
    "for rec in records:\n",
    "    producer.send(topic, rec)\n",
    "    time.sleep(0.01)\n",
    "producer.flush()\n",
    "print(f\"{len(records)} Nachrichten an Topic '{topic}' gesendet.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8c646",
   "metadata": {},
   "source": [
    "## Create a consumer and check if the messages can be read\n",
    "A Kafka consumer can subscribe to one or more topics and process the messages. Display the messages from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365a7082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erste empfangene Nachricht: {'legId': '9ca0e81111c683bec1012473feefd28f', 'searchDate': '2022-04-16', 'flightDate': '2022-04-17', 'startingAirport': 'ATL', 'destinationAirport': 'BOS', 'fareBasisCode': 'LA0NX0MC', 'travelDuration': 'PT2H29M', 'elapsedDays': 0, 'isBasicEconomy': False, 'isRefundable': False, 'isNonStop': True, 'baseFare': 217.67, 'totalFare': 248.6, 'seatsRemaining': 9, 'totalTravelDistance': 947.0, 'segmentsDepartureTimeEpochSeconds': '1650214620', 'segmentsDepartureTimeRaw': '2022-04-17T12:57:00.000-04:00', 'segmentsArrivalTimeEpochSeconds': '1650223560', 'segmentsArrivalTimeRaw': '2022-04-17T15:26:00.000-04:00', 'segmentsArrivalAirportCode': 'BOS', 'segmentsDepartureAirportCode': 'ATL', 'segmentsAirlineName': 'Delta', 'segmentsAirlineCode': 'DL', 'segmentsEquipmentDescription': 'Airbus A321', 'segmentsDurationInSeconds': '8940', 'segmentsDistance': '947', 'segmentsCabinCode': 'coach'}\n"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    \"flights\",\n",
    "    bootstrap_servers=\"172.29.16.101:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    value_deserializer=lambda v: json.loads(v.decode(\"utf-8\"))\n",
    ")\n",
    "msg = next(iter(consumer))\n",
    "print(\"Erste empfangene Nachricht:\", msg.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bdc679",
   "metadata": {},
   "source": [
    "# Kafka and Spark Streaming\n",
    "Spark can act as a Kafka consumer. This gives you the benefits of the Spark framework to process the Kafka messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ad093",
   "metadata": {},
   "source": [
    "## Spark Context and Session\n",
    "\n",
    "Initialize Spark Context and Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631aa66",
   "metadata": {},
   "source": [
    "## Create a Spark DataFrame from a Kafka stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56537216",
   "metadata": {},
   "source": [
    "## Convert the binary Kafka data to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164a982",
   "metadata": {},
   "source": [
    "## Create a structured schema for the streamed data\n",
    "\n",
    "Use objects like ```StructType```, ```StructField```, ```IntegerType```, ```BooleanType```, etc to create the schema. Afterwards apply the schema to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff75d46d",
   "metadata": {},
   "source": [
    "## Create a DataFrame grouped by a time window\n",
    "E.g., the number of messages of the different types over the last minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2b327",
   "metadata": {},
   "source": [
    "## Create a query stream of the DataFrame\n",
    "Write the output of the DataFrame to a memory sink of your choice. Use the ```start()``` method to actually start the stream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046399b",
   "metadata": {},
   "source": [
    "## Export the processed data as a Pandas DataFrame and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415318b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
